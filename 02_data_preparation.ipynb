{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:52:58.075556Z",
     "iopub.status.busy": "2024-12-23T08:52:58.075228Z",
     "iopub.status.idle": "2024-12-23T08:53:02.645948Z",
     "shell.execute_reply": "2024-12-23T08:53:02.644799Z",
     "shell.execute_reply.started": "2024-12-23T08:52:58.075527Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:02.648103Z",
     "iopub.status.busy": "2024-12-23T08:53:02.647513Z",
     "iopub.status.idle": "2024-12-23T08:53:02.652781Z",
     "shell.execute_reply": "2024-12-23T08:53:02.651595Z",
     "shell.execute_reply.started": "2024-12-23T08:53:02.648071Z"
    }
   },
   "outputs": [],
   "source": [
    "is_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "path = Path('../input/visual-taxonomy') if is_kaggle else Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:05.000137Z",
     "iopub.status.busy": "2024-12-23T08:53:04.999694Z",
     "iopub.status.idle": "2024-12-23T08:53:05.560383Z",
     "shell.execute_reply": "2024-12-23T08:53:05.559360Z",
     "shell.execute_reply.started": "2024-12-23T08:53:05.000098Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_info = pd.read_parquet(path/'category_attributes.parquet')\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:06.909667Z",
     "iopub.status.busy": "2024-12-23T08:53:06.909343Z",
     "iopub.status.idle": "2024-12-23T08:53:07.371458Z",
     "shell.execute_reply": "2024-12-23T08:53:07.369913Z",
     "shell.execute_reply.started": "2024-12-23T08:53:06.909640Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_img_path(id_, img_folder):\n",
    "    return str(path/f'{img_folder}/{str(id_).zfill(6)}.jpg')\n",
    "\n",
    "df['img_path'] = df['id'].apply(add_img_path, img_folder='train_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:09.642313Z",
     "iopub.status.busy": "2024-12-23T08:53:09.641743Z",
     "iopub.status.idle": "2024-12-23T08:53:09.650543Z",
     "shell.execute_reply": "2024-12-23T08:53:09.649269Z",
     "shell.execute_reply.started": "2024-12-23T08:53:09.642276Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self, df):\n",
    "        self.vocab = df.drop(columns=['id','len']).groupby('Category').agg(lambda col: col.unique())\n",
    "        self.label2id_map, self.id2label_map = {}, {}\n",
    "        for cat, row in self.vocab.iterrows():\n",
    "            self.label2id_map[cat] = {\n",
    "                attr:{str(label):idx for idx, label in enumerate(labels)}\n",
    "                for attr, labels in row.items()\n",
    "            }\n",
    "            self.id2label_map[cat] = {\n",
    "                attr:{idx:str(label) for idx, label in enumerate(labels)}\n",
    "                for attr, labels in row.items()\n",
    "            }\n",
    "    \n",
    "    def label2id(self, cat, attr,  label):\n",
    "        return self.label2id_map[cat][attr][label]\n",
    "\n",
    "    def id2label(self, cat, attr, id_):\n",
    "        return self.id2label_map[cat][attr][id_]\n",
    "\n",
    "    def num_classes(self, cat):\n",
    "        return [len(labels) for labels in self.vocab.loc[cat].values if len(labels)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:18.124252Z",
     "iopub.status.busy": "2024-12-23T08:53:18.123852Z",
     "iopub.status.idle": "2024-12-23T08:53:21.063262Z",
     "shell.execute_reply": "2024-12-23T08:53:21.062173Z",
     "shell.execute_reply.started": "2024-12-23T08:53:18.124218Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_labels(row, encoder):\n",
    "    cat = row['Category']\n",
    "    num_attrs = row['len']\n",
    "    ids = []\n",
    "    for i in range(num_attrs):\n",
    "        attr = f'attr_{i+1}'\n",
    "        id_ = encoder.label2id(cat, attr, str(row[attr]))\n",
    "        ids.append(id_)\n",
    "    return tuple(ids)\n",
    "\n",
    "encoder = LabelEncoder(df)\n",
    "df['labels'] = df.apply(get_labels, axis=1, encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:53:23.323669Z",
     "iopub.status.busy": "2024-12-23T08:53:23.323117Z",
     "iopub.status.idle": "2024-12-23T08:53:23.353846Z",
     "shell.execute_reply": "2024-12-23T08:53:23.352714Z",
     "shell.execute_reply.started": "2024-12-23T08:53:23.323625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Category</th>\n",
       "      <th>len</th>\n",
       "      <th>attr_1</th>\n",
       "      <th>attr_2</th>\n",
       "      <th>attr_3</th>\n",
       "      <th>attr_4</th>\n",
       "      <th>attr_5</th>\n",
       "      <th>attr_6</th>\n",
       "      <th>attr_7</th>\n",
       "      <th>attr_8</th>\n",
       "      <th>attr_9</th>\n",
       "      <th>attr_10</th>\n",
       "      <th>img_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>Men Tshirts</td>\n",
       "      <td>5</td>\n",
       "      <td>default</td>\n",
       "      <td>polo</td>\n",
       "      <td>solid</td>\n",
       "      <td>solid</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../input/visual-taxonomy/train_images/000296.jpg</td>\n",
       "      <td>(0, 1, 1, 1, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54581</th>\n",
       "      <td>54747</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>default</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>v-neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>default</td>\n",
       "      <td>solid</td>\n",
       "      <td>long sleeves</td>\n",
       "      <td>regular sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../input/visual-taxonomy/train_images/054747.jpg</td>\n",
       "      <td>(3, 1, 2, 5, 1, 1, 1, 4, 0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65146</th>\n",
       "      <td>65312</td>\n",
       "      <td>Women Tops &amp; Tunics</td>\n",
       "      <td>10</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>fitted</td>\n",
       "      <td>regular</td>\n",
       "      <td>square neck</td>\n",
       "      <td>casual</td>\n",
       "      <td>printed</td>\n",
       "      <td>default</td>\n",
       "      <td>short sleeves</td>\n",
       "      <td>puff sleeves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../input/visual-taxonomy/train_images/065312.jpg</td>\n",
       "      <td>(12, 1, 2, 6, 1, 2, 4, 1, 4, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             Category  len      attr_1  attr_2   attr_3  \\\n",
       "296      296          Men Tshirts    5     default    polo    solid   \n",
       "54581  54747  Women Tops & Tunics   10     default  fitted  regular   \n",
       "65146  65312  Women Tops & Tunics   10  multicolor  fitted  regular   \n",
       "\n",
       "            attr_4         attr_5   attr_6   attr_7         attr_8  \\\n",
       "296          solid  short sleeves      NaN      NaN            NaN   \n",
       "54581       v-neck         casual  default    solid   long sleeves   \n",
       "65146  square neck         casual  printed  default  short sleeves   \n",
       "\n",
       "                attr_9 attr_10  \\\n",
       "296                NaN     NaN   \n",
       "54581  regular sleeves     NaN   \n",
       "65146     puff sleeves     NaN   \n",
       "\n",
       "                                               img_path  \\\n",
       "296    ../input/visual-taxonomy/train_images/000296.jpg   \n",
       "54581  ../input/visual-taxonomy/train_images/054747.jpg   \n",
       "65146  ../input/visual-taxonomy/train_images/065312.jpg   \n",
       "\n",
       "                                labels  \n",
       "296                    (0, 1, 1, 1, 0)  \n",
       "54581   (3, 1, 2, 5, 1, 1, 1, 4, 0, 0)  \n",
       "65146  (12, 1, 2, 6, 1, 2, 4, 1, 4, 0)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:03.141912Z",
     "iopub.status.busy": "2024-12-23T08:58:03.141531Z",
     "iopub.status.idle": "2024-12-23T08:58:03.147600Z",
     "shell.execute_reply": "2024-12-23T08:58:03.146349Z",
     "shell.execute_reply.started": "2024-12-23T08:58:03.141874Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df, path, encoder, is_test_df=False):\n",
    "    df = df.copy()\n",
    "    img_folder = 'test_images' if is_test_df else 'train_images'\n",
    "    df['img_path'] = df['id'].apply(add_img_path, path=path, img_folder=img_folder)\n",
    "    if is_test_df: return df\n",
    "    df['labels'] = df.apply(get_labels, axis=1, encoder=encoder)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:04.721641Z",
     "iopub.status.busy": "2024-12-23T08:58:04.721293Z",
     "iopub.status.idle": "2024-12-23T08:58:20.507187Z",
     "shell.execute_reply": "2024-12-23T08:58:20.505189Z",
     "shell.execute_reply.started": "2024-12-23T08:58:04.721614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f4973f2e7e44a08c240ee8cda548f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22888caacf274e7c94fc9118b147298c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eb12a5db724091b8473a641bd31cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affd441f3dcf447f8c3edac0c9e7f5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926bd72947014fb58ed9121641c15ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipImageProcessor, BertTokenizerFast\n",
    "\n",
    "ckpt = \"Salesforce/blip-itm-base-coco\"\n",
    "img_processor = BlipImageProcessor.from_pretrained(ckpt)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:20.509678Z",
     "iopub.status.busy": "2024-12-23T08:58:20.509057Z",
     "iopub.status.idle": "2024-12-23T08:58:20.517802Z",
     "shell.execute_reply": "2024-12-23T08:58:20.515897Z",
     "shell.execute_reply.started": "2024-12-23T08:58:20.509647Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens({'additional_special_tokens':['[Encode]']})\n",
    "encode_token_id = tokenizer.convert_tokens_to_ids('[Encode]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:23.442889Z",
     "iopub.status.busy": "2024-12-23T08:58:23.442542Z",
     "iopub.status.idle": "2024-12-23T08:58:23.496994Z",
     "shell.execute_reply": "2024-12-23T08:58:23.495893Z",
     "shell.execute_reply.started": "2024-12-23T08:58:23.442861Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_question_and_tokenize(row, tokenizer, encode_token_id):\n",
    "    cat = row.name\n",
    "    attrs = row['Attribute_list']\n",
    "    question_lines = [f'For this image of {cat[:-1]}, please answer the following:']\n",
    "    question_lines.extend([f'[Encode] What is the {attr}?' for attr in attrs])\n",
    "    question = '\\n'.join(question_lines)\n",
    "    \n",
    "    tokenized = tokenizer(question, padding=True, truncation=True, return_tensors='pt')\n",
    "    tokenized['special_token_mask'] = (tokenized['input_ids']==encode_token_id).squeeze()\n",
    "    tokenized = {k:v.tolist() for k, v in tokenized.items()}\n",
    "\n",
    "    return pd.Series({**row.to_dict(), 'question':question, **tokenized})\n",
    "\n",
    "cat_info.set_index('Category', inplace=True)\n",
    "cat_info = cat_info.apply(add_question_and_tokenize, axis=1, args=(tokenizer, encode_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:27.006391Z",
     "iopub.status.busy": "2024-12-23T08:58:27.005963Z",
     "iopub.status.idle": "2024-12-23T08:58:27.012357Z",
     "shell.execute_reply": "2024-12-23T08:58:27.011008Z",
     "shell.execute_reply.started": "2024-12-23T08:58:27.006359Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_cat_info(cat_info, tokenizer):\n",
    "    cat_info = cat_info.copy()\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens':['[Encode]']})\n",
    "    encode_token_id = tokenizer.convert_tokens_to_ids('[Encode]')\n",
    "    cat_info.set_index('Category', inplace=True)\n",
    "    return cat_info.apply(add_question_and_tokenize, axis=1, args=(tokenizer, encode_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:29.665027Z",
     "iopub.status.busy": "2024-12-23T08:58:29.664617Z",
     "iopub.status.idle": "2024-12-23T08:58:29.671726Z",
     "shell.execute_reply": "2024-12-23T08:58:29.670340Z",
     "shell.execute_reply.started": "2024-12-23T08:58:29.664958Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class Batch:\n",
    "    def __init__(self, category, input_ids, special_token_mask, attention_mask, pixel_values, labels):\n",
    "        self.category = category\n",
    "        self.input_ids = input_ids\n",
    "        self.special_token_mask = special_token_mask\n",
    "        self.attention_mask = attention_mask\n",
    "        self.pixel_values = pixel_values\n",
    "        self.labels = labels\n",
    "\n",
    "    def to(self, device):\n",
    "        self.input_ids = self.input_ids.to(device)\n",
    "        self.special_token_mask = self.special_token_mask.to(device)\n",
    "        self.attention_mask = self.attention_mask.to(device)\n",
    "        self.pixel_values = self.pixel_values.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:32.346245Z",
     "iopub.status.busy": "2024-12-23T08:58:32.345804Z",
     "iopub.status.idle": "2024-12-23T08:58:32.358132Z",
     "shell.execute_reply": "2024-12-23T08:58:32.357012Z",
     "shell.execute_reply.started": "2024-12-23T08:58:32.346209Z"
    }
   },
   "outputs": [],
   "source": [
    "class MeeshoDataloader:\n",
    "    def __init__(self, df, cat_info, batch_size, img_processor):\n",
    "        self.df = df\n",
    "        self.cat_info = cat_info\n",
    "        self.bs = batch_size\n",
    "        self.img_processor = img_processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum((len(idxs)+self.bs-1)//self.bs for idxs in self.group2idxs.values())\n",
    "\n",
    "    def _sample(self):\n",
    "        group2idxs = self.df.groupby(\"Category\").apply(lambda group: group.index.tolist())\n",
    "        for cat in np.random.permutation(group2idxs.index):\n",
    "            idxs = group2idxs[cat]\n",
    "            for i in range(0, len(idxs), self.bs):\n",
    "                yield idxs[i:i+self.bs]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idxs in self._sample():\n",
    "            cat = self.df.loc[idxs[0], 'Category']\n",
    "            \n",
    "            input_ids = self.cat_info.loc[cat,'input_ids']\n",
    "            special_token_mask = self.cat_info.loc[cat,'special_token_mask']\n",
    "            attention_mask = self.cat_info.loc[cat,'attention_mask']\n",
    "            \n",
    "            images = [Image.open(path) for path in self.df.loc[idxs,'img_path']]\n",
    "            pixel_values = self.img_processor(images=images, return_tensors='pt', size=(224,224))\n",
    "            \n",
    "            labels = self.df.loc[idxs,'labels'] if 'labels' in self.df.columns else None\n",
    "            yield Batch(category=cat, input_ids=torch.tensor(input_ids),\n",
    "                        special_token_mask=torch.tensor(special_token_mask),\n",
    "                        attention_mask=torch.tensor(attention_mask),\n",
    "                        pixel_values=pixel_values.pixel_values,\n",
    "                        labels=torch.tensor(labels.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:58:33.964297Z",
     "iopub.status.busy": "2024-12-23T08:58:33.963900Z",
     "iopub.status.idle": "2024-12-23T08:58:33.969900Z",
     "shell.execute_reply": "2024-12-23T08:58:33.968272Z",
     "shell.execute_reply.started": "2024-12-23T08:58:33.964264Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dl = MeeshoDataloader(df, cat_info, batch_size=batch_size, img_processor=img_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:59:39.708171Z",
     "iopub.status.busy": "2024-12-23T08:59:39.707756Z",
     "iopub.status.idle": "2024-12-23T08:59:40.463738Z",
     "shell.execute_reply": "2024-12-23T08:59:40.462363Z",
     "shell.execute_reply.started": "2024-12-23T08:59:39.708139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Women Tshirts',\n",
       " torch.Size([32, 3, 224, 224]),\n",
       " torch.Size([78]),\n",
       " torch.Size([32, 8]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dl))\n",
    "batch.category, batch.pixel_values.size(), batch.special_token_mask.size(), batch.labels.size()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
