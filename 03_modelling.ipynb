{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:06:34.284227Z",
     "iopub.status.busy": "2024-12-23T09:06:34.283923Z",
     "iopub.status.idle": "2024-12-23T09:06:38.502017Z",
     "shell.execute_reply": "2024-12-23T09:06:38.500792Z",
     "shell.execute_reply.started": "2024-12-23T09:06:34.284200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:06:38.503834Z",
     "iopub.status.busy": "2024-12-23T09:06:38.503303Z",
     "iopub.status.idle": "2024-12-23T09:06:38.530218Z",
     "shell.execute_reply": "2024-12-23T09:06:38.529068Z",
     "shell.execute_reply.started": "2024-12-23T09:06:38.503800Z"
    }
   },
   "outputs": [],
   "source": [
    "is_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "path = Path('../input/visual-taxonomy') if is_kaggle else Path('data')\n",
    "\n",
    "if is_kaggle:\n",
    "    src_path = Path('../input/attribute-extraction-meesho/src')\n",
    "    from shutil import copytree\n",
    "    copytree(src = src_path, dst = \"../working/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:06:38.531692Z",
     "iopub.status.busy": "2024-12-23T09:06:38.531310Z",
     "iopub.status.idle": "2024-12-23T09:06:38.541640Z",
     "shell.execute_reply": "2024-12-23T09:06:38.540352Z",
     "shell.execute_reply.started": "2024-12-23T09:06:38.531644Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data_preparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:09:35.557568Z",
     "iopub.status.busy": "2024-12-23T09:09:35.557186Z",
     "iopub.status.idle": "2024-12-23T09:09:36.081311Z",
     "shell.execute_reply": "2024-12-23T09:09:36.080190Z",
     "shell.execute_reply.started": "2024-12-23T09:09:35.557544Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_info = pd.read_parquet(path/'category_attributes.parquet')\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-23T09:09:43.134631Z",
     "iopub.status.busy": "2024-12-23T09:09:43.134277Z",
     "iopub.status.idle": "2024-12-23T09:09:56.566965Z",
     "shell.execute_reply": "2024-12-23T09:09:56.565719Z",
     "shell.execute_reply.started": "2024-12-23T09:09:43.134605Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e38bce6710e4ee7a2c85cb6c25780ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccca2c1d6ba74452b0dbcb2b01ead586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d71096482546ad9fcf0d64b0094d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275a882940164fd0b4ca99609743fc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9669c92279414f898640eeddb61bac73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipImageProcessor, BertTokenizerFast\n",
    "\n",
    "ckpt = \"Salesforce/blip-itm-base-coco\"\n",
    "img_processor = BlipImageProcessor.from_pretrained(ckpt)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:09:59.975650Z",
     "iopub.status.busy": "2024-12-23T09:09:59.974953Z",
     "iopub.status.idle": "2024-12-23T09:10:03.199127Z",
     "shell.execute_reply": "2024-12-23T09:10:03.198031Z",
     "shell.execute_reply.started": "2024-12-23T09:09:59.975614Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder(df)\n",
    "df_processed = process_df(df, path, encoder=label_encoder)\n",
    "cat_info_processed = process_cat_info(cat_info, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:10:11.899716Z",
     "iopub.status.busy": "2024-12-23T09:10:11.899337Z",
     "iopub.status.idle": "2024-12-23T09:10:12.033645Z",
     "shell.execute_reply": "2024-12-23T09:10:12.032758Z",
     "shell.execute_reply.started": "2024-12-23T09:10:11.899686Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dl = MeeshoDataloader(df_processed, cat_info_processed, batch_size=batch_size, img_processor=img_processor)\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:10:20.353772Z",
     "iopub.status.busy": "2024-12-23T09:10:20.353410Z",
     "iopub.status.idle": "2024-12-23T09:10:20.360434Z",
     "shell.execute_reply": "2024-12-23T09:10:20.359367Z",
     "shell.execute_reply.started": "2024-12-23T09:10:20.353736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 82]), torch.Size([4, 3, 224, 224]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.input_ids.size(), batch.pixel_values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:10:26.229946Z",
     "iopub.status.busy": "2024-12-23T09:10:26.229462Z",
     "iopub.status.idle": "2024-12-23T09:10:31.397515Z",
     "shell.execute_reply": "2024-12-23T09:10:31.396367Z",
     "shell.execute_reply.started": "2024-12-23T09:10:26.229910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c745b06b44f4f6985e37be0f6c4dc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30523, 768, padding_idx=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, BlipTextModel, BlipVisionModel\n",
    "\n",
    "config = AutoConfig.from_pretrained(ckpt)\n",
    "vision_model = BlipVisionModel(config.vision_config)\n",
    "text_encoder = BlipTextModel(config.text_config, add_pooling_layer=False)\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:10:33.699800Z",
     "iopub.status.busy": "2024-12-23T09:10:33.699367Z",
     "iopub.status.idle": "2024-12-23T09:10:35.385282Z",
     "shell.execute_reply": "2024-12-23T09:10:35.384102Z",
     "shell.execute_reply.started": "2024-12-23T09:10:33.699763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 197, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_outputs = vision_model(\n",
    "    pixel_values=batch.pixel_values,\n",
    "    output_attentions=config.output_attentions,\n",
    "    output_hidden_states=config.output_hidden_states,\n",
    "    interpolate_pos_encoding=False,\n",
    ")\n",
    "image_embeds = vision_outputs[0]\n",
    "image_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:14:00.974035Z",
     "iopub.status.busy": "2024-12-23T09:14:00.973639Z",
     "iopub.status.idle": "2024-12-23T09:14:02.036397Z",
     "shell.execute_reply": "2024-12-23T09:14:02.035373Z",
     "shell.execute_reply.started": "2024-12-23T09:14:00.974002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 82, 768]), torch.Size([4, 9, 768]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_atts = torch.ones(image_embeds.size()[:-1], dtype=torch.long)\n",
    "\n",
    "text_outputs = text_encoder(\n",
    "    input_ids=batch.input_ids,\n",
    "    attention_mask=batch.attention_mask,\n",
    "    encoder_hidden_states=image_embeds,\n",
    "    encoder_attention_mask=image_atts,\n",
    ")\n",
    "question_embeds = text_outputs[0]\n",
    "attr_embeds = question_embeds[:, batch.special_token_mask, :]\n",
    "question_embeds.size(), attr_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:11:04.366582Z",
     "iopub.status.busy": "2024-12-23T09:11:04.366177Z",
     "iopub.status.idle": "2024-12-23T09:11:04.380066Z",
     "shell.execute_reply": "2024-12-23T09:11:04.379093Z",
     "shell.execute_reply.started": "2024-12-23T09:11:04.366551Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "embed_size = config.text_config.hidden_size\n",
    "heads = {}\n",
    "for cat in label_encoder.vocab.index:\n",
    "    heads[cat] = [nn.Linear(embed_size, n) for n in label_encoder.num_classes(cat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:39:45.028665Z",
     "iopub.status.busy": "2024-12-23T09:39:45.028296Z",
     "iopub.status.idle": "2024-12-23T09:39:45.033697Z",
     "shell.execute_reply": "2024-12-23T09:39:45.032598Z",
     "shell.execute_reply.started": "2024-12-23T09:39:45.028631Z"
    }
   },
   "outputs": [],
   "source": [
    "attr_loss = torch.ones(attr_embeds.size()[1], dtype=torch.float32)\n",
    "preds = torch.ones(attr_embeds.size()[:-1], dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:39:45.326363Z",
     "iopub.status.busy": "2024-12-23T09:39:45.325907Z",
     "iopub.status.idle": "2024-12-23T09:39:45.346433Z",
     "shell.execute_reply": "2024-12-23T09:39:45.345100Z",
     "shell.execute_reply.started": "2024-12-23T09:39:45.326325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2601, grad_fn=<SelectBackward0>)\n",
      "tensor(1.2027, grad_fn=<SelectBackward0>)\n",
      "tensor(0.7630, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5768, grad_fn=<SelectBackward0>)\n",
      "tensor(0.8727, grad_fn=<SelectBackward0>)\n",
      "tensor(0.9106, grad_fn=<SelectBackward0>)\n",
      "tensor(1.0647, grad_fn=<SelectBackward0>)\n",
      "tensor(1.0684, grad_fn=<SelectBackward0>)\n",
      "tensor(0.8854, grad_fn=<SelectBackward0>)\n",
      "tensor(1.1783, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, head in enumerate(heads[batch.category]):\n",
    "    logits = head(attr_embeds[:, i, :])\n",
    "    preds[:, i] = logits.argmax(dim=1)\n",
    "    \n",
    "    attr_loss[i] = nn.CrossEntropyLoss()(logits, batch.labels[:,i])\n",
    "    print(attr_loss[i])\n",
    "\n",
    "loss = attr_loss.mean()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:32:52.878218Z",
     "iopub.status.busy": "2024-12-23T09:32:52.877793Z",
     "iopub.status.idle": "2024-12-23T09:32:52.885209Z",
     "shell.execute_reply": "2024-12-23T09:32:52.884039Z",
     "shell.execute_reply.started": "2024-12-23T09:32:52.878183Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from transformers.utils import ModelOutput\n",
    "\n",
    "@dataclass\n",
    "class BlipAttributeExtractionModelOutput(ModelOutput):\n",
    "    preds: torch.FloatTensor\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    attr_loss: Optional[torch.FloatTensor] = None\n",
    "    image_embeds: Optional[torch.FloatTensor] = None\n",
    "    question_embeds: Optional[torch.FloatTensor] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:43:06.869758Z",
     "iopub.status.busy": "2024-12-23T09:43:06.869360Z",
     "iopub.status.idle": "2024-12-23T09:43:06.880063Z",
     "shell.execute_reply": "2024-12-23T09:43:06.878770Z",
     "shell.execute_reply.started": "2024-12-23T09:43:06.869725Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BlipPreTrainedModel\n",
    "\n",
    "class BlipForAttributeExtraction(BlipPreTrainedModel):\n",
    "    def __init__(self, config, tokenizer, label_encoder):\n",
    "        super().__init__(config)\n",
    "        self.vision_model = BlipVisionModel(config.vision_config)\n",
    "        self.text_encoder = BlipTextModel(config.text_config, add_pooling_layer=False)\n",
    "        self.text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        embed_size = config.text_config.hidden_size\n",
    "        self.heads = {}\n",
    "        for cat in label_encoder.vocab.index:\n",
    "            self.heads[cat] = [nn.Linear(embed_size, n) for n in label_encoder.num_classes(cat)]\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        image_embeds = self.vision_model(pixel_values=batch.pixel_values,\n",
    "                                         output_attentions=self.config.output_attentions,\n",
    "                                         output_hidden_states=self.config.output_hidden_states,\n",
    "                                         interpolate_pos_encoding=False)[0]\n",
    "        image_atts = torch.ones(image_embeds.size()[:-1], dtype=torch.long)\n",
    "        \n",
    "        question_embeds = self.text_encoder(input_ids=batch.input_ids,\n",
    "                                            attention_mask=batch.attention_mask,\n",
    "                                            encoder_hidden_states=image_embeds,\n",
    "                                            encoder_attention_mask=image_atts)[0]\n",
    "        attr_embeds = question_embeds[:, batch.special_token_mask, :]\n",
    "\n",
    "        attr_loss = torch.ones(attr_embeds.size()[1], dtype=torch.float32)\n",
    "        preds = torch.ones(attr_embeds.size()[:-1], dtype=torch.int8)\n",
    "        \n",
    "        for i, head in enumerate(self.heads[batch.category]):\n",
    "            logits = head(attr_embeds[:, i, :])\n",
    "            preds[:, i] = logits.argmax(dim=1)\n",
    "            if batch.labels is not None:\n",
    "                attr_loss[i] = nn.CrossEntropyLoss()(logits.cpu(), batch.labels[:,i])\n",
    "        loss = attr_loss.mean() if batch.labels is not None else None\n",
    "\n",
    "        return BlipAttributeExtractionModelOutput(loss=loss, attr_loss=attr_loss,\n",
    "                                                  preds=preds, image_embeds=image_embeds,\n",
    "                                                  question_embeds=question_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:43:07.432458Z",
     "iopub.status.busy": "2024-12-23T09:43:07.432122Z",
     "iopub.status.idle": "2024-12-23T09:43:09.802349Z",
     "shell.execute_reply": "2024-12-23T09:43:09.801260Z",
     "shell.execute_reply.started": "2024-12-23T09:43:07.432434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BlipForAttributeExtraction were not initialized from the model checkpoint at Salesforce/blip-itm-base-coco and are newly initialized because the shapes did not match:\n",
      "- text_encoder.embeddings.word_embeddings.weight: found shape torch.Size([30524, 768]) in the checkpoint and torch.Size([30523, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = BlipForAttributeExtraction.from_pretrained(\n",
    "    ckpt, config=config, label_encoder=label_encoder,\n",
    "    tokenizer=tokenizer, ignore_mismatched_sizes=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:43:09.804636Z",
     "iopub.status.busy": "2024-12-23T09:43:09.804213Z",
     "iopub.status.idle": "2024-12-23T09:43:11.944413Z",
     "shell.execute_reply": "2024-12-23T09:43:11.943475Z",
     "shell.execute_reply.started": "2024-12-23T09:43:09.804595Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:43:13.794600Z",
     "iopub.status.busy": "2024-12-23T09:43:13.794236Z",
     "iopub.status.idle": "2024-12-23T09:43:13.801247Z",
     "shell.execute_reply": "2024-12-23T09:43:13.800106Z",
     "shell.execute_reply.started": "2024-12-23T09:43:13.794571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 9]), torch.Size([4, 9]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.preds.size(), batch.labels.size()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9755748,
     "sourceId": 84705,
     "sourceType": "competition"
    },
    {
     "datasetId": 6349956,
     "sourceId": 10277124,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
